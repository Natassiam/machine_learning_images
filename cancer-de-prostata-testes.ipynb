{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#BASIC\nimport numpy as np \nimport pandas as pd \nimport os\n\n# DATA visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport PIL  #https://en.wikipedia.org/wiki/Python_Imaging_Library\nfrom IPython.display import Image, display\n\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\n\nimport openslide\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-11T15:13:33.651878Z","iopub.execute_input":"2021-08-11T15:13:33.652167Z","iopub.status.idle":"2021-08-11T15:13:37.901818Z","shell.execute_reply.started":"2021-08-11T15:13:33.652136Z","shell.execute_reply":"2021-08-11T15:13:37.900598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\nhttps://plotly.com/python/plotly-express/#:~:text=Basic%20Charts%20tutorials.-,Overview,for%20creating%20most%20common%20figures.\n\nhttps://pypi.org/project/plotly-express/\n\nhttps://github.com/plotly/plotly_express\n\nhttps://medium.com/plotly/introducing-plotly-express-808df010143d\n","metadata":{}},{"cell_type":"markdown","source":"https://en.wikipedia.org/wiki/Python_Imaging_Library\n\n**Python Imaging Library (PIL)** é uma biblioteca adicional gratuita e de código aberto para a linguagem de programação Python que adiciona suporte para abrir, manipular e salvar muitos formatos de arquivo de imagem diferentes.\n","metadata":{}},{"cell_type":"code","source":"BASE_FOLDER = \"/kaggle/input/prostate-cancer-grade-assessment/\"\n#!ls {BASE_FOLDER}","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-08-11T15:13:37.905100Z","iopub.execute_input":"2021-08-11T15:13:37.905486Z","iopub.status.idle":"2021-08-11T15:13:37.909764Z","shell.execute_reply.started":"2021-08-11T15:13:37.905445Z","shell.execute_reply":"2021-08-11T15:13:37.908905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask_dir = f'{BASE_FOLDER}/train_label_masks'","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:13:37.910922Z","iopub.execute_input":"2021-08-11T15:13:37.911146Z","iopub.status.idle":"2021-08-11T15:13:37.925119Z","shell.execute_reply.started":"2021-08-11T15:13:37.911117Z","shell.execute_reply":"2021-08-11T15:13:37.923690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(BASE_FOLDER+\"train.csv\")\ntest = pd.read_csv(BASE_FOLDER+\"test.csv\")\nsub = pd.read_csv(BASE_FOLDER+\"sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:13:37.926572Z","iopub.execute_input":"2021-08-11T15:13:37.926828Z","iopub.status.idle":"2021-08-11T15:13:38.013669Z","shell.execute_reply.started":"2021-08-11T15:13:37.926797Z","shell.execute_reply":"2021-08-11T15:13:38.012314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:13:38.067307Z","iopub.execute_input":"2021-08-11T15:13:38.067822Z","iopub.status.idle":"2021-08-11T15:13:38.094470Z","shell.execute_reply.started":"2021-08-11T15:13:38.067783Z","shell.execute_reply":"2021-08-11T15:13:38.093552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = train.groupby('isup_grade').count()['image_id'].reset_index().sort_values(by='image_id',ascending=False)\ntemp.style.background_gradient(cmap='Purples')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:13:38.096028Z","iopub.execute_input":"2021-08-11T15:13:38.096300Z","iopub.status.idle":"2021-08-11T15:13:38.236301Z","shell.execute_reply.started":"2021-08-11T15:13:38.096271Z","shell.execute_reply":"2021-08-11T15:13:38.235264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now Let's Look at the gleason score distribution as well","metadata":{}},{"cell_type":"code","source":"temp = train.groupby('gleason_score').count()['image_id'].reset_index().sort_values(by='image_id',ascending=False)\ntemp.style.background_gradient(cmap='Reds')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:13:38.237698Z","iopub.execute_input":"2021-08-11T15:13:38.237936Z","iopub.status.idle":"2021-08-11T15:13:38.272496Z","shell.execute_reply.started":"2021-08-11T15:13:38.237909Z","shell.execute_reply":"2021-08-11T15:13:38.271598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From this graph it is also clear that the data will be baised towards non-cancer examples","metadata":{}},{"cell_type":"code","source":"'''\nExample for using Openslide to display an image\n'''\n\n\n# Open the image (does not yet read the image into memory)\nexample = openslide.OpenSlide(os.path.join(BASE_FOLDER+\"train_images\", '005e66f06bce9c2e49142536caf2f6ee.tiff'))\n\n\n# Read a specific region of the image starting at upper left coordinate (x=17800, y=19500) on level 0 and extracting a 256*256 pixel patch.\n# At this point image data is read from the file and loaded into memory.\npatch = example.read_region((17800,19500), 0, (256, 256))\n\n\n# Display the image\ndisplay(patch)\n\n# Close the opened slide after use\nexample.close()\n","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:13:38.273550Z","iopub.execute_input":"2021-08-11T15:13:38.273771Z","iopub.status.idle":"2021-08-11T15:13:38.539748Z","shell.execute_reply.started":"2021-08-11T15:13:38.273742Z","shell.execute_reply":"2021-08-11T15:13:38.534222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Agora vamos ver todas as informações que podemos obter de uma imagem depois de criar um objeto Openslide","metadata":{}},{"cell_type":"code","source":"train = train.set_index('image_id')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:13:38.541033Z","iopub.execute_input":"2021-08-11T15:13:38.541336Z","iopub.status.idle":"2021-08-11T15:13:38.556593Z","shell.execute_reply.started":"2021-08-11T15:13:38.541295Z","shell.execute_reply":"2021-08-11T15:13:38.555139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_values(image,max_size=(600,400)):\n    slide = openslide.OpenSlide(os.path.join(BASE_FOLDER+\"train_images\", f'{image}.tiff'))\n    \n    # Here we compute the \"pixel spacing\": the physical size of a pixel in the image.\n    # OpenSlide gives the resolution in centimeters so we convert this to microns.\n    f,ax =  plt.subplots(2 ,figsize=(6,16))\n    spacing = 1 / (float(slide.properties['tiff.XResolution']) / 10000)\n    \n    # Read a specific region of the image starting at upper left coordinate (x=17800, y=19500) on level 0 and extracting a 256*256 pixel patch.\n    # At this point image data is read from the file and loaded into memory.\n    patch = slide.read_region((1780,1950), 0, (256, 256)) #ZOOMED FIGURE\n    \n    ax[0].imshow(patch) \n    ax[0].set_title('Zoomed Image')\n    \n    \n    ax[1].imshow(slide.get_thumbnail(size=max_size)) #UNZOOMED FIGURE\n    ax[1].set_title('Full Image')\n    \n    \n    print(f\"File id: {slide}\")\n    print(f\"Dimensions: {slide.dimensions}\")\n    print(f\"Microns per pixel / pixel spacing: {spacing:.3f}\")\n    print(f\"Number of levels in the image: {slide.level_count}\")\n    print(f\"Downsample factor per level: {slide.level_downsamples}\")\n    print(f\"Dimensions of levels: {slide.level_dimensions}\\n\\n\")\n    \n  \n    print(f\"ISUP grade: {train.loc[image, 'isup_grade']}\")\n    print(f\"Gleason score: {train.loc[image, 'gleason_score']}\")","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:13:38.557955Z","iopub.execute_input":"2021-08-11T15:13:38.558352Z","iopub.status.idle":"2021-08-11T15:13:38.571035Z","shell.execute_reply.started":"2021-08-11T15:13:38.558315Z","shell.execute_reply":"2021-08-11T15:13:38.570226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_values('07a7ef0ba3bb0d6564a73f4f3e1c2293')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:13:38.572182Z","iopub.execute_input":"2021-08-11T15:13:38.572448Z","iopub.status.idle":"2021-08-11T15:13:39.522953Z","shell.execute_reply.started":"2021-08-11T15:13:38.572416Z","shell.execute_reply":"2021-08-11T15:13:39.522348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_values('0018ae58b01bdadc8e347995b69f99aa')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:13:39.523998Z","iopub.execute_input":"2021-08-11T15:13:39.524329Z","iopub.status.idle":"2021-08-11T15:13:40.110302Z","shell.execute_reply.started":"2021-08-11T15:13:39.524301Z","shell.execute_reply":"2021-08-11T15:13:40.108989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_values('035b1edd3d1aeeffc77ce5d248a01a53')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:13:40.111665Z","iopub.execute_input":"2021-08-11T15:13:40.111896Z","iopub.status.idle":"2021-08-11T15:13:40.844820Z","shell.execute_reply.started":"2021-08-11T15:13:40.111867Z","shell.execute_reply":"2021-08-11T15:13:40.844273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_values('06a0cbd8fd6320ef1aa6f19342af2e68')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:13:40.845919Z","iopub.execute_input":"2021-08-11T15:13:40.846256Z","iopub.status.idle":"2021-08-11T15:13:41.624696Z","shell.execute_reply.started":"2021-08-11T15:13:40.846222Z","shell.execute_reply":"2021-08-11T15:13:41.623913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_values('0838c82917cd9af681df249264d2769c')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:13:41.625679Z","iopub.execute_input":"2021-08-11T15:13:41.625853Z","iopub.status.idle":"2021-08-11T15:13:42.411681Z","shell.execute_reply.started":"2021-08-11T15:13:41.625832Z","shell.execute_reply":"2021-08-11T15:13:42.410534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Agora vamos dar uma olhada nas imagens ampliadas com ISUP e gleason_score diferentes\n","metadata":{}},{"cell_type":"code","source":"def display_images(images):\n    '''\n   Esta função recebe uma lista de imagens. Em seguida, itera através da imagem criando objetos de slides abertos, nos quais diferentes funções\n     para obter informações pode ser chamado mais tarde\n    '''\n    f, ax = plt.subplots(5,3, figsize=(18,22))\n    for i, image in enumerate(images):\n        \n        slide = openslide.OpenSlide(os.path.join(BASE_FOLDER+\"train_images\", f'{image}.tiff')) # Making Openslide Object\n        \n        #Here we compute the \"pixel spacing\": the physical size of a pixel in the image,\n        #OpenSlide gives the resolution in centimeters so we convert this to microns\n        \n        spacing = 1/(float(slide.properties['tiff.XResolution']) / 10000)\n        patch = slide.read_region((1780,1950), 0, (256, 256)) #Reading the image as before betweeen x=1780 to y=1950 and of pixel size =256*256\n        \n        ax[i//3, i%3].imshow(patch) #Displaying Image\n        slide.close()       \n        ax[i//3, i%3].axis('off')\n        \n        image_id = image\n        data_provider = train.loc[image, 'data_provider']\n        isup_grade = train.loc[image, 'isup_grade']\n        gleason_score = train.loc[image, 'gleason_score']\n        ax[i//3, i%3].set_title(f\"ID: {image_id}\\nSource: {data_provider} ISUP: {isup_grade} Gleason: {gleason_score}\")\n\n    plt.show() ","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:13:42.413383Z","iopub.execute_input":"2021-08-11T15:13:42.413684Z","iopub.status.idle":"2021-08-11T15:13:42.427800Z","shell.execute_reply.started":"2021-08-11T15:13:42.413652Z","shell.execute_reply":"2021-08-11T15:13:42.426418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = [\n'07a7ef0ba3bb0d6564a73f4f3e1c2293',\n    '037504061b9fba71ef6e24c48c6df44d',\n    '035b1edd3d1aeeffc77ce5d248a01a53',\n    '059cbf902c5e42972587c8d17d49efed',\n    '06a0cbd8fd6320ef1aa6f19342af2e68',\n    '06eda4a6faca84e84a781fee2d5f47e1',\n    '0a4b7a7499ed55c71033cefb0765e93d',\n    '0838c82917cd9af681df249264d2769c',\n    '046b35ae95374bfb48cdca8d7c83233f',\n    '074c3e01525681a275a42282cd21cbde',\n    '05abe25c883d508ecc15b6e857e59f32',\n    '05f4e9415af9fdabc19109c980daf5ad',\n    '060121a06476ef401d8a21d6567dee6d',\n    '068b0e3be4c35ea983f77accf8351cc8',\n    '08f055372c7b8a7e1df97c6586542ac8'\n]\n\ndisplay_images(images)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:13:42.429311Z","iopub.execute_input":"2021-08-11T15:13:42.429578Z","iopub.status.idle":"2021-08-11T15:13:45.625774Z","shell.execute_reply.started":"2021-08-11T15:13:42.429550Z","shell.execute_reply":"2021-08-11T15:13:45.625012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"OBSERVAÇÕES:\n\n* As dimensões da imagem são bastante grandes (normalmente entre 5.000 e 40.000 pixels em x e y).\n* Cada slide tem 3 níveis que você pode carregar, correspondendo a uma redução da resolução de 1, 4 e 16. Os níveis intermediários podem ser criados reduzindo a resolução para um nível de resolução mais alto.\n* As dimensões de cada nível diferem com base nas dimensões da imagem original.\n* As biópsias podem ser em diferentes rotações. Essa rotação não tem valor clínico e depende apenas de como a biópsia foi coletada no laboratório.\n* Existem diferenças de cor perceptíveis entre as biópsias, isso é muito comum na patologia e é causado por diferentes procedimentos laboratoriais.","metadata":{}},{"cell_type":"markdown","source":"O que são máscaras?\n\nAlém do rótulo no nível do slide (presente no arquivo csv), quase todos os slides do conjunto de treinamento têm uma máscara associada com informações adicionais do rótulo. Essas máscaras indicam diretamente quais partes do tecido são saudáveis ​​e quais são cancerosas. Essas máscaras são fornecidas para ajudar no desenvolvimento de estratégias para selecionar as subamostras mais úteis das imagens.","metadata":{}},{"cell_type":"code","source":"example_mask =  openslide.OpenSlide(os.path.join(mask_dir, f'{\"00412139e6b04d1e1cee8421f38f6e90\"}_mask.tiff'))\ndisplay(example_mask.get_thumbnail(size=(600,400)))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:13:45.627080Z","iopub.execute_input":"2021-08-11T15:13:45.627535Z","iopub.status.idle":"2021-08-11T15:13:45.772323Z","shell.execute_reply.started":"2021-08-11T15:13:45.627498Z","shell.execute_reply":"2021-08-11T15:13:45.771337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Imagem Preta!\nAs Máscaras para Trem estão no formato RGB, conforme dito pelos organizadores.\n\nIsso acontece pelos dois motivos a seguir:\n\n* As informações do rótulo são armazenadas no canal vermelho (R), os outros canais são * definidos como zero e podem ser ignorados *.\n\n* As máscaras não são dados de imagem como os WSI. São apenas matrizes com valores baseados nas informações do provedor de dados fornecidas acima, em vez de conter uma faixa de valores de 0 a 255, elas vão até no máximo 6, representando o rótulos de classe diferentes (verifique a descrição do conjunto de dados para obter detalhes sobre rótulos de máscara). Portanto, quando você tentar visualizar a máscara, ela aparecerá muito escura, pois todos os valores estão próximos de 0. Aplicar o mapa de cores corrige o problema atribuindo a cada rótulo entre 0 e 6 uma cor distinta.\n\nEntão o que precisamos fazer é ler o arquivo de imagem usando o objeto openslide, tirar os valores do Nível Vermelho e então aplicar cmap a ele\n\nUsando uma pequena função auxiliar, podemos exibir algumas informações básicas sobre uma máscara. Para inspecionar as máscaras com mais facilidade, mapeamos os rótulos internos para cores RGB usando uma paleta de cores. Se você preferir algo como matplotlib, você também pode usar plt.imshow () para mostrar diretamente uma máscara (sem convertê-la em uma imagem RGB).","metadata":{}},{"cell_type":"code","source":"import matplotlib\n\ndef display_masks(slides):    \n    f, ax = plt.subplots(5,3, figsize=(18,22))\n    for i, slide in enumerate(slides):\n        \n        mask = openslide.OpenSlide(os.path.join(mask_dir, f'{slide}_mask.tiff'))\n        mask_data = mask.read_region((0,0), mask.level_count - 1, mask.level_dimensions[-1])\n        cmap = matplotlib.colors.ListedColormap(['black', 'gray', 'green', 'yellow', 'orange', 'red'])\n\n        ax[i//3, i%3].imshow(np.asarray(mask_data)[:,:,0], cmap=cmap, interpolation='nearest', vmin=0, vmax=6) \n        mask.close()       \n        ax[i//3, i%3].axis('off')\n        \n        image_id = slide\n        data_provider = train.loc[slide, 'data_provider']\n        isup_grade = train.loc[slide, 'isup_grade']\n        gleason_score = train.loc[slide, 'gleason_score']\n        ax[i//3, i%3].set_title(f\"ID: {image_id}\\nSource: {data_provider} ISUP: {isup_grade} Gleason: {gleason_score}\")\n        f.tight_layout()\n        \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:13:45.773600Z","iopub.execute_input":"2021-08-11T15:13:45.773786Z","iopub.status.idle":"2021-08-11T15:13:45.783138Z","shell.execute_reply.started":"2021-08-11T15:13:45.773765Z","shell.execute_reply":"2021-08-11T15:13:45.782328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_masks(images) #Visualizing Only six Examples","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:13:45.784203Z","iopub.execute_input":"2021-08-11T15:13:45.784534Z","iopub.status.idle":"2021-08-11T15:13:50.473094Z","shell.execute_reply.started":"2021-08-11T15:13:45.784507Z","shell.execute_reply":"2021-08-11T15:13:50.471964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Comparando as imagens**\n\n","metadata":{}},{"cell_type":"code","source":"Aumentando a quantidade de vmax conseguiremos visualizar os perfis aproximados de padrões das células que compõem o tecido.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mask_img(image,max_size=(400,400)):\n    \n    slide = openslide.OpenSlide(os.path.join(BASE_FOLDER+\"train_images\", f'{image}.tiff'))\n    mask =  openslide.OpenSlide(os.path.join(mask_dir, f'{image}_mask.tiff'))\n    \n    # Here we compute the \"pixel spacing\": the physical size of a pixel in the image.\n    # OpenSlide gives the resolution in centimeters so we convert this to microns.\n    f,ax =  plt.subplots(1,2 ,figsize=(18,22))\n    spacing = 1 / (float(slide.properties['tiff.XResolution']) / 10000)\n    img = slide.get_thumbnail(size=(200,300)) #IMAGE \n    \n    mask_data = mask.read_region((0,0), mask.level_count - 1, mask.level_dimensions[-1])\n    cmap = matplotlib.colors.ListedColormap(['black', 'gray', 'green', 'yellow', 'orange', 'red'])\n    \n    ax[0].imshow(img) \n    #ax[0].set_title('Image')\n    \n    \n    ax[1].imshow(np.asarray(mask_data)[:,:,0], cmap=cmap, interpolation='nearest', vmin=0, vmax=4) #IMAGE MASKS\n    #ax[1].set_title('Image_MASK')\n    \n    \n    image_id = image\n    data_provider = train.loc[image, 'data_provider']\n    isup_grade = train.loc[image, 'isup_grade']\n    gleason_score = train.loc[image, 'gleason_score']\n    ax[0].set_title(f\"ID: {image_id}\\nSource: {data_provider} ISUP: {isup_grade} Gleason: {gleason_score} IMAGE\")\n    ax[1].set_title(f\"ID: {image_id}\\nSource: {data_provider} ISUP: {isup_grade} Gleason: {gleason_score} IMAGE_MASK\")","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:27:26.418577Z","iopub.execute_input":"2021-08-11T15:27:26.418848Z","iopub.status.idle":"2021-08-11T15:27:26.432044Z","shell.execute_reply.started":"2021-08-11T15:27:26.418820Z","shell.execute_reply":"2021-08-11T15:27:26.430872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask_img('07a7ef0ba3bb0d6564a73f4f3e1c2293')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:27:31.089975Z","iopub.execute_input":"2021-08-11T15:27:31.090578Z","iopub.status.idle":"2021-08-11T15:27:31.817312Z","shell.execute_reply.started":"2021-08-11T15:27:31.090547Z","shell.execute_reply":"2021-08-11T15:27:31.816081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images1= [\n    '046b35ae95374bfb48cdca8d7c83233f',\n    '068b0e3be4c35ea983f77accf8351cc8'\n]\n\nfor image in images1:\n    mask_img(image)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:27:37.365079Z","iopub.execute_input":"2021-08-11T15:27:37.365354Z","iopub.status.idle":"2021-08-11T15:27:38.382232Z","shell.execute_reply.started":"2021-08-11T15:27:37.365326Z","shell.execute_reply":"2021-08-11T15:27:38.380777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#pip install -Iv tensorflow_estimator==1.13.0","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:13:52.587441Z","iopub.execute_input":"2021-08-11T15:13:52.587737Z","iopub.status.idle":"2021-08-11T15:13:52.591836Z","shell.execute_reply.started":"2021-08-11T15:13:52.587708Z","shell.execute_reply":"2021-08-11T15:13:52.591031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" #pip install --upgrade tensorflow","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:14:00.207537Z","iopub.status.idle":"2021-08-11T15:14:00.207967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainDF #drop([7273],inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T15:14:00.234716Z","iopub.status.idle":"2021-08-11T15:14:00.235138Z"},"trusted":true},"execution_count":null,"outputs":[]}]}